{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68a1295b-f12d-4678-8dfa-f63c9d6c0bca",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "619e943e-b878-4321-b078-bb4cb06dbdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from public_tests import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82a6700-8fe7-4f2d-9085-6e466b8be4c9",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "## 2 -  Problem Statement\n",
    "\n",
    "Suppose you are starting a company that grows and sells wild mushrooms. \n",
    "- Since not all mushrooms are edible, you'd like to be able to tell whether a given mushroom is edible or poisonous based on it's physical attributes\n",
    "- You have some existing data that you can use for this task. \n",
    "\n",
    "Can you use the data to help you identify which mushrooms can be sold safely? \n",
    "\n",
    "Note: The dataset used is for illustrative purposes only. It is not meant to be a guide on identifying edible mushrooms.\n",
    "\n",
    "\n",
    "\n",
    "<a name=\"3\"></a>\n",
    "## 3 - Dataset\n",
    "\n",
    "You will start by loading the dataset for this task. The dataset you have collected is as follows:\n",
    "\n",
    "| Cap Color | Stalk Shape | Solitary | Edible |\n",
    "|:---------:|:-----------:|:--------:|:------:|\n",
    "|   Brown   |   Tapering  |    Yes   |    1   |\n",
    "|   Brown   |  Enlarging  |    Yes   |    1   |\n",
    "|   Brown   |  Enlarging  |    No    |    0   |\n",
    "|   Brown   |  Enlarging  |    No    |    0   |\n",
    "|   Brown   |   Tapering  |    Yes   |    1   |\n",
    "|    Red    |   Tapering  |    Yes   |    0   |\n",
    "|    Red    |  Enlarging  |    No    |    0   |\n",
    "|   Brown   |  Enlarging  |    Yes   |    1   |\n",
    "|    Red    |   Tapering  |    No    |    1   |\n",
    "|   Brown   |  Enlarging  |    No    |    0   |\n",
    "\n",
    "\n",
    "-  You have 10 examples of mushrooms. For each example, you have\n",
    "    - Three features\n",
    "        - Cap Color (`Brown` or `Red`),\n",
    "        - Stalk Shape (`Tapering` or `Enlarging`), and\n",
    "        - Solitary (`Yes` or `No`)\n",
    "    - Label\n",
    "        - Edible (`1` indicating yes or `0` indicating poisonous)\n",
    "\n",
    "<a name=\"3.1\"></a>\n",
    "### 3.1 One hot encoded dataset\n",
    "For ease of implementation, we have one-hot encoded the features (turned them into 0 or 1 valued features)\n",
    "\n",
    "| Brown Cap | Tapering Stalk Shape | Solitary | Edible |\n",
    "|:---------:|:--------------------:|:--------:|:------:|\n",
    "|     1     |           1          |     1    |    1   |\n",
    "|     1     |           0          |     1    |    1   |\n",
    "|     1     |           0          |     0    |    0   |\n",
    "|     1     |           0          |     0    |    0   |\n",
    "|     1     |           1          |     1    |    1   |\n",
    "|     0     |           1          |     1    |    0   |\n",
    "|     0     |           0          |     0    |    0   |\n",
    "|     1     |           0          |     1    |    1   |\n",
    "|     0     |           1          |     0    |    1   |\n",
    "|     1     |           0          |     0    |    0   |\n",
    "\n",
    "Therefore,\n",
    "- `X_train` contains three features for each example \n",
    "    - Brown Color (A value of `1` indicates \"Brown\" cap color and `0` indicates \"Red\" cap color)\n",
    "    - Tapering Shape (A value of `1` indicates \"Tapering Stalk Shape\" and `0` indicates \"Enlarging\" stalk shape)\n",
    "    - Solitary  (A value of `1` indicates \"Yes\" and `0` indicates \"No\")\n",
    "\n",
    "- `y_train` is whether the mushroom is edible \n",
    "    - `y = 1` indicates edible\n",
    "    - `y = 0` indicates poisonous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d2d9b95-837c-452f-88c3-cc0c7857b6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[1,1,1],[1,0,1],[1,0,0],[1,0,0],[1,1,1],[0,1,1],[0,0,0],[1,0,1],[0,1,0],[1,0,0]])\n",
    "y_train = np.array([1,1,0,0,1,0,0,1,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a23c9107-7529-49d5-a8cc-b417bfba159b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e5bbe32-8a9c-40f5-9ed4-9e85d59ebb62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "598e3a28-107d-4153-b846-aa852bb0c6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1],\n",
       "       [1, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:4, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81aaefc9-f018-491d-98cb-badf6178dd1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74100a75-6e2d-4fa6-9ee8-425caf0ebe8a",
   "metadata": {},
   "source": [
    "### The steps for making the decision treee are  \n",
    "- Start by all examples at the root node\n",
    "- Calculate information gain for splitting on all possible features, and pick the one with the highest information gain\n",
    "- Split dataset according to the selected feature, and create left and right branches of the tree\n",
    "- Keep repeating splitting process until stopping criteria is met"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f4f2c7-674f-4259-b4f7-45ea17d8a5a7",
   "metadata": {},
   "source": [
    "### First we will implement the `compute_entropy()` function  \n",
    "This function will take the target values as input and will give the calculated entropy as the output.  \n",
    "The entropy can be calculated by the formula  \n",
    "$$ H(p_1) = -p_1\\text{log}_2(p_1) - (1 - p_1)\\text{log}_2(1 - p_1)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e981dcd-b9ad-42a6-9cd1-c74fbcab259b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_entropy(y):\n",
    "    if len(y) != 0:\n",
    "        p1 = len(y[y==1]) / len(y)\n",
    "        if p1 != 0 and p1 != 1:\n",
    "            entropy = -p1 * np.log2(p1) - (1 - p1) * np.log2(1 - p1)\n",
    "            return entropy\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6dee96a-67ae-40c2-8b7c-dc733704057c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy at root node:  1.0\n",
      "\u001b[92m All tests passed.\n"
     ]
    }
   ],
   "source": [
    "print(\"Entropy at root node: \", compute_entropy(y_train)) \n",
    "\n",
    "# UNIT TESTS\n",
    "compute_entropy_test(compute_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cd0eb7-a6d3-4479-a2fe-5c9af29bc8b1",
   "metadata": {},
   "source": [
    "### Create a function `split_dataset` to split the dataset into right and left subparts  \n",
    "- The function will take the features, list of indices and feature as input\n",
    "- The function will return the indices corresponding the left and right indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7acf7ac9-7ef9-4b98-8376-4d2280bb09b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, node_indices, feature):\n",
    "    left_indices = []\n",
    "    right_indices = []\n",
    "    \n",
    "    for index in node_indices:\n",
    "        if X[index, feature] == 1:\n",
    "            left_indices.append(index)\n",
    "        else:\n",
    "            right_indices.append(index)\n",
    "    return left_indices, right_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed4e7936-6cef-417d-a8f8-f32ef57cf73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left indices:  [0, 1, 2, 3, 4, 7, 9]\n",
      "Right indices:  [5, 6, 8]\n",
      "\u001b[92m All tests passed.\n"
     ]
    }
   ],
   "source": [
    "root_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "feature = 0\n",
    "\n",
    "left_indices, right_indices = split_dataset(X_train, root_indices, feature)\n",
    "\n",
    "print(\"Left indices: \", left_indices)\n",
    "print(\"Right indices: \", right_indices)\n",
    "\n",
    "# UNIT TESTS    \n",
    "split_dataset_test(split_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92978a54-22fe-4a71-b67f-0ae2b3ab003f",
   "metadata": {},
   "source": [
    "### Create a fuction `compute_information_gain` which will calculate the information gain for every step  \n",
    "- The information gain takes the features, target, node_indices and feature as the input\n",
    "- The function returns the information gain for split.\n",
    "\n",
    "The formula for calculating the information gain is  \n",
    "$$\\text{Information Gain} = H(p_1^{node}) - (w^{left}H(p_1^{left}) + w^{right}H(p_1^{right}))$$  \n",
    "where  \n",
    "$H(p_1^{node})$ = Entropy of the node which is to be splitted  \n",
    "$w^{left}$ and $w^{right}$ are the proportions of the examples on left and right, respectively.  \n",
    "$H(p_1^{left})$ and $H(p_1^{right})$ are the entropy of examples on left and right, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cea3f343-e51e-44a3-9197-944f2423cb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_information_gain(X, y, node_indices, feature):\n",
    "    # split the dataset\n",
    "    left_indices, right_indices = split_dataset(X, node_indices, feature)\n",
    "\n",
    "    # Get the features and targets for splitted dataset to pass them as argument to the funcitons\n",
    "    X_node, y_node = X[node_indices], y[node_indices]\n",
    "    X_left, y_left = X[left_indices], y[left_indices]\n",
    "    X_right, y_right = X[right_indices], y[right_indices]\n",
    "\n",
    "    # Calculate Entopies\n",
    "    node_entropy = compute_entropy(y_node)\n",
    "    l_node_entropy = compute_entropy(y_left) \n",
    "    r_node_entropy = compute_entropy(y_right)\n",
    "\n",
    "    # Calculate proportions of the splitted data\n",
    "    w_left = len(X_left) / len(X_node)\n",
    "    w_right = len(X_right) / len(X_node)\n",
    "\n",
    "    # Calculate the information gain\n",
    "    information_gain = node_entropy - (w_left * l_node_entropy + w_right * r_node_entropy)\n",
    "\n",
    "    return information_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df92d9d1-63a2-4bc2-97ea-db3cec0e10e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Gain from splitting the root on brown cap:  0.034851554559677034\n",
      "Information Gain from splitting the root on tapering stalk shape:  0.12451124978365313\n",
      "Information Gain from splitting the root on solitary:  0.2780719051126377\n",
      "\u001b[92m All tests passed.\n"
     ]
    }
   ],
   "source": [
    "info_gain0 = compute_information_gain(X_train, y_train, root_indices, feature=0)\n",
    "print(\"Information Gain from splitting the root on brown cap: \", info_gain0)\n",
    "    \n",
    "info_gain1 = compute_information_gain(X_train, y_train, root_indices, feature=1)\n",
    "print(\"Information Gain from splitting the root on tapering stalk shape: \", info_gain1)\n",
    "\n",
    "info_gain2 = compute_information_gain(X_train, y_train, root_indices, feature=2)\n",
    "print(\"Information Gain from splitting the root on solitary: \", info_gain2)\n",
    "\n",
    "# UNIT TESTS\n",
    "compute_information_gain_test(compute_information_gain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940c3dd9-3784-4bb1-ae34-079309e9ccf4",
   "metadata": {},
   "source": [
    "### Write a function `get_best_split` which will get the best split by calculating information gain for all the possible splits on the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04783eef-bf7a-4648-a265-2d19474fa68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_split(X, y, node_indices):\n",
    "    features = X.shape[1]\n",
    "    best_feature = -1\n",
    "    max_info_gain = 0\n",
    "    for i in range(features):\n",
    "        info_gain = compute_information_gain(X, y, node_indices, i)\n",
    "        if info_gain > max_info_gain:\n",
    "            max_info_gain = info_gain\n",
    "            best_feature = i\n",
    "    return best_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2dbbee5c-7070-4b1a-b19d-0bb8a2d4e073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best feature to split on: 2\n",
      "\u001b[92m All tests passed.\n"
     ]
    }
   ],
   "source": [
    "best_feature = get_best_split(X_train, y_train, root_indices)\n",
    "print(\"Best feature to split on: %d\" % best_feature)\n",
    "\n",
    "# UNIT TESTS\n",
    "get_best_split_test(get_best_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e607fb7-6d2f-409b-861a-2ef9d75bc668",
   "metadata": {},
   "source": [
    "## Now as all the helper functions are ready lets build the `Decision Tree`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "332602cb-00cb-46fe-a2be-8882c088ff76",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = []\n",
    "\n",
    "def build_tree_recursive(X, y, node_indices, branch_name, max_depth, current_depth):\n",
    "    if current_depth == max_depth:\n",
    "        formatting = \" \"*current_depth + \"-\"*current_depth\n",
    "        print(formatting, \"%s leaf node with indices\" % branch_name, node_indices)\n",
    "        return\n",
    "\n",
    "    best_feature = get_best_split(X, y, node_indices)\n",
    "    tree.append((current_depth, branch_name, node_indices, best_feature))\n",
    "\n",
    "    formatting = \"-\"*current_depth\n",
    "    print(\"%s Depth %d, %s : split on feature: %d\" % (formatting, current_depth, branch_name, best_feature))\n",
    "    \n",
    "    left_indices, right_indices = split_dataset(X, node_indices, best_feature)\n",
    "    build_tree_recursive(X, y, left_indices, \"Left\", 2, current_depth + 1)\n",
    "    build_tree_recursive(X, y, right_indices, \"Rigth\", 2, current_depth + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53bc66f0-4ff5-4f67-acc3-d7f6b331f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Depth 0, Root : split on feature: 2\n",
      "- Depth 1, Left : split on feature: 0\n",
      "  -- Left leaf node with indices [0, 1, 4, 7]\n",
      "  -- Rigth leaf node with indices [5]\n",
      "- Depth 1, Rigth : split on feature: 1\n",
      "  -- Left leaf node with indices [8]\n",
      "  -- Rigth leaf node with indices [2, 3, 6, 9]\n"
     ]
    }
   ],
   "source": [
    "build_tree_recursive(X_train, y_train, root_indices, \"Root\", max_depth=2, current_depth=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcf50fe-9dfa-44c6-9407-4b5612902df2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
